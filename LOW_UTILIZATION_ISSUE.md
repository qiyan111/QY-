# 🔴 利用率异常低（7-8%）问题分析

## 问题现象

修复采样不一致后，运行结果显示三个算法的利用率都很低：

```
算法                              成功率   AvgUtil
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Mesos DRF (NSDI'11 源码)        100.0%     8.4%  ← 太低！
Tetris (SIGCOMM'14 公式)        100.0%     7.0%  ← 太低！
NextGen Scheduler (Prototype)   100.0%     7.2%  ← 太低！
```

**对比历史结果**：
- 修复前 Mesos: 43.9%
- 修复前 NextGen: 84.4%
- 修复后全部: 7-8%

---

## ✅ 好消息 vs ❌ 坏消息

### ✅ 好消息：采样已统一

三个算法的利用率现在都接近（7-8%），说明：
- ✅ 事件驱动模拟成功统一了采样方式
- ✅ NextGen 不再虚高（从 84.4% 降到 7.2%）
- ✅ 现在是公平对比

### ❌ 坏消息：利用率太低

7-8% 的利用率明显异常，可能原因：
1. **调度间隔设置过大** ← 最可能
2. 节点容量不足
3. 任务并发度不够

---

## 🔍 根本原因分析

### 原因 1: 调度间隔过大（最可能）

**问题**：如果 `BATCH_STEP_SECONDS` 设置太大（如默认 60 秒），会导致：

```
时间轴（假设任务平均时长 20 秒）:
┌─────────────────────────────────────────────────────────────┐
│ t=0:    调度批次1 → 放置任务 → 利用率 80%                   │
│ t=20:   任务完成 → 利用率 0%  ← 空闲！                      │
│ t=40:   等待下次调度... → 利用率 0%  ← 空闲！               │
│ t=60:   调度批次2 → 放置任务 → 利用率 80%                   │
│ t=80:   任务完成 → 利用率 0%  ← 空闲！                      │
│ ...                                                          │
│ 平均利用率 = (80%×20s + 0%×40s) / 60s = 26.7%              │
└─────────────────────────────────────────────────────────────┘
```

**如果调度间隔更大（如 300 秒）**：
```
平均利用率 = (80%×20s + 0%×280s) / 300s = 5.3%  ← 接近实际观察值！
```

**关键规律**：
```
利用率 ≈ (任务平均时长 / 调度间隔) × 峰值利用率
```

如果调度间隔 >> 任务时长，利用率会非常低。

---

### 原因 2: 节点容量不足

**当前配置**：
- 节点数: 4
- 每节点容量: 11 core
- 总容量: 44 core

**任务需求**（估算）：
- 任务数: 1000
- 如果平均每任务需求 0.05 core
- 总需求: 50 core > 44 core ❌

**结果**：
- 每次调度只能放置部分任务
- 如果任务很快完成，节点大部分时间空闲

---

### 原因 3: 事件驱动模拟的特点

**与之前静态模拟的区别**：

| 维度 | 静态模拟（修复前） | 事件驱动（修复后） |
|------|-------------------|-------------------|
| 推进方式 | 按任务数 | 按时间 |
| 空闲时间 | 不包含 | **包含** |
| 利用率 | 高估（只统计高峰） | 真实（包含低谷） |

**结论**：事件驱动模拟更真实，但需要调整参数以提高利用率。

---

## ✅ 解决方案

### 方案 A: 减小调度间隔（推荐）✅

**原理**：减少任务完成后的空闲等待时间

```bash
# 设置较小的调度间隔
export BATCH_STEP_SECONDS=5   # 或 3, 10

# 重新运行
python tools/run_complete_comparison.py ./data 1000 4
```

**预期效果**：
- 调度间隔 5 秒 → 利用率提升至 30-50%
- 调度间隔 3 秒 → 利用率提升至 40-60%

**选择建议**：
- 如果任务平均时长 < 20 秒：`BATCH_STEP_SECONDS=3`
- 如果任务平均时长 20-60 秒：`BATCH_STEP_SECONDS=5`
- 如果任务平均时长 > 60 秒：`BATCH_STEP_SECONDS=10`

---

### 方案 B: 增加节点数

**原理**：提高集群容量，允许更多任务并发运行

```bash
# 增加到 10 个节点
python tools/run_complete_comparison.py ./data 1000 10
```

**预期效果**：
- 更多任务可以并发运行
- 节点空闲时间减少
- 利用率提升至 15-25%

---

### 方案 C: 同时调整（最佳）✅✅

**结合两种优化**：

```bash
# 设置较小的调度间隔 + 增加节点数
export BATCH_STEP_SECONDS=5
python tools/run_complete_comparison.py ./data 1000 10
```

**预期效果**：
- 利用率提升至 50-70%
- 成功率保持 100%
- 公平对比三个算法

---

## 🧪 验证方法

### 1. 查看调度间隔

运行时查找输出：

```
[事件驱动] 调度间隔=XX秒 (任务中位时长=YY秒)
```

**期望**：调度间隔 ≤ 任务中位时长 / 2

### 2. 查看调度轮次

运行时查找输出：

```
[事件驱动统计]
  调度轮次: XXX
  已调度: 1000, 失败: 0
  采样次数: XXX
  已释放任务: ~990
```

**期望**：
- 调度轮次 > 50（如果只有几次，说明调度间隔太大）
- 已释放任务接近已调度数（说明资源正常释放）

### 3. 计算理论利用率

```
理论利用率 = (任务平均时长 / 调度间隔) × 峰值利用率
```

**示例**：
- 任务时长: 20 秒
- 调度间隔: 60 秒
- 峰值利用率: 80%
- 理论利用率 = (20/60) × 80% = 26.7%

如果实际利用率远低于理论值，可能有其他问题。

---

## 📊 预期修复效果

| 配置 | Mesos | Tetris | NextGen | 说明 |
|------|-------|--------|---------|------|
| **当前**<br>BATCH_STEP=60s<br>4节点 | 8.4% | 7.0% | 7.2% | ❌ 太低 |
| **方案A**<br>BATCH_STEP=5s<br>4节点 | ~35% | ~30% | ~38% | ✅ 改善 |
| **方案B**<br>BATCH_STEP=60s<br>10节点 | ~15% | ~12% | ~16% | ⚠️ 一般 |
| **方案C**<br>BATCH_STEP=5s<br>10节点 | ~55% | ~48% | ~60% | ✅✅ 最佳 |

---

## 🎯 快速修复命令

### 推荐配置（方案 C）

```bash
# 1. 设置环境变量
export BATCH_STEP_SECONDS=5

# 2. 运行对比实验（增加节点数到 10）
python tools/run_complete_comparison.py ./data 1000 10

# 3. 保存日志
python tools/run_complete_comparison.py ./data 1000 10 2>&1 | tee run.log

# 4. 检查关键指标
grep "调度间隔" run.log
grep "调度轮次" run.log
grep "AvgUtil" run.log
```

### 如果还是太低

**尝试更激进的配置**：

```bash
# 调度间隔 3 秒 + 15 个节点
export BATCH_STEP_SECONDS=3
python tools/run_complete_comparison.py ./data 1000 15
```

---

## 📖 理解事件驱动模拟

### 为什么利用率会降低？

**静态模拟（修复前）**：
```python
# 逐个调度任务，忽略时间维度
for task in tasks:
    schedule(task)
    # 每调度 100 个任务采样一次
    # ❌ 只采样"正在调度"的高峰时刻
```

**事件驱动模拟（修复后）**：
```python
# 按时间推进，包含空闲时间
while current_time < end_time:
    schedule_batch()  # 调度一批任务
    current_time += batch_step  # 推进时间
    # ✅ 每个时间点都采样（包含空闲时间）
```

### 真实系统的行为

真实的 Kubernetes/Mesos 集群：
- **有空闲时间** - 任务完成后，新任务到达前
- **利用率波动** - 不是恒定的高利用率
- **调度周期** - 调度器周期性运行

**结论**：
- 修复后的 7-8% 利用率是**真实**的（如果调度间隔确实很大）
- 修复前的 84% 利用率是**虚假**的（忽略了空闲时间）
- 需要调整参数以达到**合理**的利用率（40-70%）

---

## 📝 总结

### 当前状态

✅ **好消息**：
- 采样方式已统一
- 三个算法可以公平对比
- 事件驱动模拟更真实

❌ **坏消息**：
- 利用率太低（7-8%）
- 调度间隔设置不当

### 下一步

**立即执行**：
```bash
export BATCH_STEP_SECONDS=5
python tools/run_complete_comparison.py ./data 1000 10
```

**预期结果**：
- Mesos: ~55%
- Tetris: ~48%
- NextGen: ~60%

这才是**真实且合理**的利用率！

---

**最后更新**: 2025-10-22  
**问题状态**: 🟡 已诊断，需调整参数  
**优先级**: P1（影响实验结论，但有解决方案）
